---
- hosts: localhost
  vars:
    crawler_count: 2
    redis_count: "{{ 1 if crawler_count|int > 0 else 0 }}"
  gather_facts: false
  module_defaults:
    amazon.aws.ec2:
      instance_type: t2.micro
      # wait:  "{{ True if crawler_count|int > 0 else False }}"
      wait: true
      region: us-east-2
      image: ami-0a91cd140a1fc148a
      key_name: ec2-general
  tasks:
    - ec2:
        count_tag:
          Name: crawler
        instance_tags:
          Name: crawler
        exact_count: "{{ crawler_count }}"
      register: ec2
    - add_host:
        hostname: "{{ item.public_ip }}"
        group: crawlers
      loop: "{{ ec2.tagged_instances }}"
    - ec2:
        count_tag:
          Name: redis
        instance_tags:
          Name: redis
        exact_count: "{{ redis_count }}"
      register: ec2
    - add_host:
        hostname: "{{ item.public_ip }}"
        group: redis
      loop: "{{ ec2.tagged_instances }}"
    - debug:
        var: groups

- hosts: redis
  remote_user: ubuntu
  become: true
  tasks:
    - apt: name=redis state=present update_cache=true 
    - service: name=redis state=started

- hosts: crawlers
  vars:
    project_dir: /home/ubuntu/distributed-crawl-demo
  remote_user: ubuntu
  tasks:
    - apt: name=python3-pip state=present update_cache=true 
      become: true
    - git:
        repo: https://github.com/psacawa/distributed-crawl-demo
        dest: "{{ project_dir }}"
    - pip:
        requirements:  "{{ project_dir }}/requirements.txt"
    - command: python3 -m scrapy crawl dmoz
      args:
        chdir: "{{ project_dir }}"
      environment:
        REDIS_HOST: "{{ groups.redis[0] }}"
